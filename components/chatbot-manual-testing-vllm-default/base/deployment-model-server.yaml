apiVersion: apps/v1
kind: Deployment
metadata:
  labels: 
    app.kubernetes.io/instance: chatbot-manual-testing-vllm-default-model-server
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/name:  chatbot-manual-testing-vllm-default-model-server
    app.kubernetes.io/part-of: chatbot-manual-testing-vllm-default  
  name: chatbot-manual-testing-vllm-default-model-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance:  chatbot-manual-testing-vllm-default-model-server 
  template:
    metadata: 
      labels:
        app.kubernetes.io/instance:  chatbot-manual-testing-vllm-default-model-server
    spec:
      containers:
      - image: quay.io/rh-aiservices-bu/vllm-openai-ubi9:0.4.2
        args: [
            "--model",
            "instructlab/granite-7b-lab",
            "--port",
            "8001",
            "--download-dir",
            "/models-cache",
            "--max-model-len",
            "4096"]
        resources:
          limits:
            nvidia.com/gpu: '1'
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        - name: models-cache
          mountPath: /models-cache
        name: app-model-service
        ports:
        - containerPort: 8001
        securityContext:
          runAsNonRoot: true
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: "2Gi"
      - name: models-cache
        persistentVolumeClaim:
          claimName: chatbot-manual-testing-vllm-default

      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
